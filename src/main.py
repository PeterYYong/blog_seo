import sys
import os
import json
import pandas as pd
import argparse
from datetime import datetime
import time

# --- ê²½ë¡œ ì„¤ì • (ê°€ì¥ ì¤‘ìš”) ---
# í˜„ì¬ íŒŒì¼(main.py)ì˜ ìœ„ì¹˜ë¥¼ ê°•ì œë¡œ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€í•©ë‹ˆë‹¤.
# ì´ë ‡ê²Œ í•˜ë©´ "src." ê°™ì€ ì ‘ë‘ì‚¬ ì—†ì´ ê·¸ëƒ¥ íŒŒì¼ ì´ë¦„ë§Œ ë¶€ë¥´ë©´ ë©ë‹ˆë‹¤.
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

try:
    # ê°™ì€ í´ë”(src)ì— ìˆëŠ” ëª¨ë“ˆë“¤ì„ ì§ì ‘ í˜¸ì¶œ
    from keyword_expander import expand_keyword
    from data_fetcher import fetch_keyword_data
    from calculator import calculate_saturation, calculate_efficiency, filter_keywords
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}")
    print(f"í˜„ì¬ 'src' í´ë” ì•ˆì— ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”:")
    print(f" - keyword_expander.py")
    print(f" - data_fetcher.py")
    print(f" - calculator.py")
    sys.exit(1)

def main():
    parser = argparse.ArgumentParser(description="Naver SEO Keyword Miner (Real Data Mode)")
    parser.add_argument("--seed", type=str, default="ìº í•‘ì˜ì", help="Seed keyword for mining")
    args = parser.parse_args()

    print(f"ğŸ¤– [ë‹¥í„°ìŠ¤í†¤ Real-Data ì—ì´ì „íŠ¸] ê°€ë™ ì‹œì‘...")

    # 1. ì‹œë“œ í‚¤ì›Œë“œ ì •ì˜
    seed_keyword = args.seed
    print(f"ğŸ¯ ì‹œë“œ í‚¤ì›Œë“œ: {seed_keyword}")
    
    # 2. í‚¤ì›Œë“œ í™•ì¥ (ë¸Œë ˆì¸ìŠ¤í† ë°)
    print("   â†³ í‚¤ì›Œë“œ í™•ì¥ ë° ë¸Œë ˆì¸ìŠ¤í† ë° ì¤‘...")
    keywords, sub_topics = expand_keyword(seed_keyword)
    
    if sub_topics:
        print(f"   âœ¨ [Auto-Brainstorming] ëŒ€ì£¼ì œ ê°ì§€! -> {len(sub_topics)}ê°œ í•˜ìœ„ ì£¼ì œë¡œ í™•ì¥ë¨.")
        print(f"      {sub_topics}")
    
    # 3. ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ (REAL API)
    print(f"   ğŸ“¡ ë„¤ì´ë²„ API ì ‘ì† ì¤‘... (ì´ {len(keywords)}ê°œ í‚¤ì›Œë“œ)")
    data = []
    
    # for i, kw in enumerate(keywords):
    #     print(f"      [{i+1}/{len(keywords)}] '{kw}' ë°ì´í„° ì¡°íšŒ ì¤‘...", end="\r")
    #     try:
    #         # fetch_keyword_dataëŠ” ë‚´ë¶€ì ìœ¼ë¡œ secrets.jsonì„ ë¡œë“œí•©ë‹ˆë‹¤.
    #         metrics = fetch_keyword_data(kw)
    #         if metrics:
    #             data.append(metrics)
    #     except Exception as e:
    #         print(f"\n      âŒ Error fetching '{kw}': {e}")
        
    #     # API ê³¼ë¶€í•˜ ë°©ì§€ (ì‚´ì§ í…€ì„ ì¤Œ)
    #     time.sleep(0.1) 
    for i, kw in enumerate(keywords):
            print(f"      [{i+1}/{len(keywords)}] '{kw}' ë°ì´í„° ì¡°íšŒ ì¤‘...", end=" ") # end="\r" ì œê±°
            try:
                metrics = fetch_keyword_data(kw)
                if metrics:
                    data.append(metrics)
                    
                    # [ğŸ”¥ ê²€ì¦ ì½”ë“œ ì¶”ê°€] : ì´ ë¶€ë¶„ì´ í•µì‹¬ì…ë‹ˆë‹¤!
                    vol = metrics['Monthly_Search_Volume']
                    docs = metrics['Total_Docs']
                    print(f"ğŸ‘‰ [ê²€ìƒ‰ëŸ‰: {vol:,} / ë¬¸ì„œìˆ˜: {docs:,}]")  
                    
            except Exception as e:
                print(f"\n      âŒ Error fetching '{kw}': {e}")
            
            time.sleep(0.1)
        
    print("\n   âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ.")
    
    if not data:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. secrets.json ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    df = pd.DataFrame(data)
    
    # 4. ì§€í‘œ ê³„ì‚° (ë³€ìˆ˜ëª… ë§¤ì¹­: Monthly_Search_Volume, Total_Docs)
    print("   ğŸ§® ì•Œê³ ë¦¬ì¦˜ ê³„ì‚° ì¤‘ (Sk, Ek)...")
    try:
        df['Saturation_Index'] = df.apply(lambda row: calculate_saturation(row['Total_Docs'], row['Monthly_Search_Volume']), axis=1)
        df['Efficiency_Score'] = df.apply(lambda row: calculate_efficiency(row['Saturation_Index'], row['Monthly_Search_Volume']), axis=1)
    except KeyError as e:
        print(f"âŒ ë°ì´í„° ì»¬ëŸ¼ ì´ë¦„ ë¶ˆì¼ì¹˜ ì—ëŸ¬: {e}")
        print("data_fetcher.pyê°€ ë°˜í™˜í•˜ëŠ” í‚¤ ê°’(Key)ì„ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # 5. í•„í„°ë§ (Sk < 5.0)
    initial_count = len(df)
    df_filtered = filter_keywords(df) # calculator.pyì˜ í•¨ìˆ˜ ì‚¬ìš©
    dropped_count = initial_count - len(df_filtered)
    
    if dropped_count > 0:
        print(f"   ğŸ—‘ï¸ ë ˆë“œì˜¤ì…˜ í‚¤ì›Œë“œ {dropped_count}ê°œ ì œê±°ë¨ (Sk >= 5.0)")
    
    # 6. ì •ë ¬ (íš¨ìœ¨ì„± ìˆœ)
    df_filtered = df_filtered.sort_values(by='Efficiency_Score', ascending=False)
    
    # 7. ë¦¬í¬íŠ¸ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    os.makedirs('reports', exist_ok=True)
    report_filename = f"reports/result_REAL_{timestamp}.md"
    
    # ë³´ê¸° ì¢‹ê²Œ ë°˜ì˜¬ë¦¼
    display_df = df_filtered.copy()
    display_df['Saturation_Index'] = display_df['Saturation_Index'].round(2)
    display_df['Efficiency_Score'] = display_df['Efficiency_Score'].round(2)
    
    # Markdown ë³€í™˜
    try:
        markdown_table = display_df[['Keyword', 'Monthly_Search_Volume', 'Total_Docs', 'Saturation_Index', 'Efficiency_Score', 'SmartBlock_Type']].to_markdown(index=False)
    except ImportError:
        markdown_table = display_df.to_string()

    brainstorm_section = ""
    if sub_topics:
        brainstorm_section = f"""
> [!TIP]
> **Auto-Brainstorming Activated**
> ì…ë ¥í•˜ì‹  ëŒ€ì£¼ì œ **'{seed_keyword}'**ì— ëŒ€í•´ ë‹¤ìŒ ì„¸ë¶€ ì£¼ì œë¡œ í™•ì¥ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤:
> {', '.join(sub_topics)}
"""

    report_content = f"""# SEO Keyword Analysis Report (REAL DATA)
**Timestamp:** {timestamp}
**Seed Keyword:** {seed_keyword}
{brainstorm_section}
## Analysis Summary
- **Total Keywords Analyzed:** {initial_count}
- **Keywords Passed Filter (Sk < 5.0):** {len(df_filtered)}
- **Drop Rate:** {dropped_count / initial_count * 100:.1f}%

## Recommended Keywords (Sorted by Efficiency Ek)

| Note |
| --- |
| **Sk (Saturation Index)** | `< 0.5` Blue Ocean, `0.5 ~ 1.0` Good, `1.0 ~ 5.0` Competitive |
| **Ek (Efficiency Score)** | Higher is better. Balancing volume, conversion, and competition. |

{markdown_table}

## Next Actions
- Select top 3 keywords with high `Ek` and `Sk < 1.0`.
- Create content targeting the identified `SmartBlock Type`.
"""
    
    with open(report_filename, "w", encoding="utf-8") as f:
        f.write(report_content)
        
    print(f"âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_filename}")

if __name__ == "__main__":
    main()